# ğŸ§  Machine Learning From Scratch

A curated collection of classical machine learning algorithms implemented **entirely from scratch** using Python and NumPy.

No `scikit-learn`.
No `tensorflow`.
No black boxes.

This repository focuses on **mechanical understanding**, not API usage.

---

## ğŸ¯ Motivation

Most machine learning resources teach how to *use* models, not how they *work*.

This project exists to:

* Expose the full training loop of each algorithm
* Make optimization and loss functions explicit
* Reveal numerical and statistical failure modes
* Build intuition through visualization and experimentation

If you can implement it from scratch, you understand it.

---

## ğŸ“š Algorithms Implemented

### ğŸ§ª Supervised Learning

#### Regression

* Linear Regression (Normal Equation)
* Linear Regression (Gradient Descent)
* Ridge Regression
* Lasso Regression
* Polynomial Regression

#### Classification

* Logistic Regression
* k-Nearest Neighbors (k-NN)
* Naive Bayes (Gaussian)
* Perceptron
* Support Vector Machine (Linear)

---

### ğŸ” Unsupervised Learning

* K-Means Clustering
* Principal Component Analysis (PCA)
* Hierarchical Clustering (Agglomerative)

---

### âš™ï¸ Optimization Algorithms

* Batch Gradient Descent
* Stochastic Gradient Descent
* Mini-batch Gradient Descent

---

### ğŸ“Š Evaluation Metrics

* Accuracy
* Precision
* Recall
* F1-score
* Confusion Matrix
* Mean Squared Error (MSE)
* Cross-Entropy Loss

---

## ğŸ—‚ï¸ Project Structure

```
ml-from-scratch/
â”‚
â”œâ”€â”€ algorithms/
â”‚   â”œâ”€â”€ regression/
â”‚   â”‚   â”œâ”€â”€ linear_regression.py
â”‚   â”‚   â”œâ”€â”€ logistic_regression.py
â”‚   â”‚   â””â”€â”€ ridge_lasso.py
â”‚   â”‚
â”‚   â”œâ”€â”€ classification/
â”‚   â”‚   â”œâ”€â”€ knn.py
â”‚   â”‚   â”œâ”€â”€ naive_bayes.py
â”‚   â”‚   â”œâ”€â”€ perceptron.py
â”‚   â”‚   â””â”€â”€ svm.py
â”‚   â”‚
â”‚   â””â”€â”€ unsupervised/
â”‚       â”œâ”€â”€ kmeans.py
â”‚       â”œâ”€â”€ pca.py
â”‚       â””â”€â”€ hierarchical.py
â”‚
â”œâ”€â”€ optimization/
â”‚   â”œâ”€â”€ gradient_descent.py
â”‚   â””â”€â”€ loss_functions.py
â”‚
â”œâ”€â”€ metrics/
â”‚   â””â”€â”€ evaluation.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_utils.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ regression_demo.ipynb
â”‚   â”œâ”€â”€ classification_demo.ipynb
â”‚   â””â”€â”€ clustering_demo.ipynb
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_models.py
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ§© Design Philosophy

* **Explicit over implicit** â€“ every operation is visible
* **Readable over clever** â€“ clarity beats abstraction
* **Educational over optimized** â€“ performance is secondary
* **Deterministic behavior** â€“ controlled randomness where applicable

---

## ğŸ” Example: Logistic Regression

Each implementation includes:

* Manual sigmoid computation
* Binary cross-entropy loss
* Gradient derivation and update
* Decision threshold tuning
* Confusion matrix analysis
* Visualization of predictions

Nothing is hidden behind helper libraries.

---

## ğŸ› ï¸ Technologies & Dependencies

### Core Technologies

* ğŸ **Python**
* ğŸ““ **Jupyter Notebooks**

### Dependencies (Minimal by design)

```
numpy
matplotlib
```

Optional (for notebooks):

```
jupyter
```

---

## ğŸš€ Installation

```bash
git clone https://github.com/your-username/ml-from-scratch.git
cd ml-from-scratch
pip install -r requirements.txt
```

---

## â–¶ï¸ How to Use

* Run individual `.py` scripts directly
* Explore algorithm behavior through Jupyter notebooks
* Modify loss functions, learning rates, or initialization to observe effects

This repository is designed for experimentation.

---

## ğŸ‘¥ Intended Audience

* Students learning machine learning fundamentals
* Engineers preparing for ML interviews
* Practitioners who want to understand models beyond library calls

This is not a production ML framework.

---

## âš ï¸ Known Limitations

* Not optimized for large-scale datasets
* No GPU acceleration
* No deep learning models

These constraints are intentional.

---

## ğŸ“„ License

MIT License â€” free to use, modify, and distribute for educational purposes.
